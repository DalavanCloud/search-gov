#!/usr/bin/env ruby  

require 'rubygems'
require 'date'
require 'json'
require 'open-uri'
require 'nokogiri' 


MEDLINE_XML_BASE_URL = "http://www.nlm.nih.gov/medlineplus/xml/vocabulary/mplus_"

# groups.xml
# vocab.xml


class MedlineVocab

  SATURDAY = 6
  DAYS_PER_WEEK = 7

  CACHE_DATA_PATH = "."

  def self.saturday_on_or_before( date )

	day_of_week = date.wday 

	most_recent_saturday = if day_of_week >= SATURDAY
		date - day_of_week + SATURDAY
	else
		date - day_of_week - DAYS_PER_WEEK + SATURDAY
	end

  end

  def initialize( xml_data )
	@xml_data = xml_data
	@doc = Nokogiri::XML( xml_data )
  end

  def self.for_date( date = nil )
	most_recent_saturday = saturday_on_or_before( date || Date.today )
	sat_s = most_recent_saturday.strftime( "%Y-%m-%d" )
	vocab_xml_fns = "vocab_#{sat_s}.xml"
	cached_data_path = File.join( CACHE_DATA_PATH, vocab_xml_fns )
	xml_data = if File.exist?( cached_data_path )
		File.open( cached_data_path ) { |cached_file| cached_file.read }	
	else
		vocab_xml_url = "#{MEDLINE_XML_BASE_URL}#{vocab_xml_fns}"
		puts "fetching #{vocab_xml_url}"
		remote_data = open( vocab_xml_url ) { |remote| remote.read }
		File.open( cached_data_path, "w" ) { |cached_data_file| cached_data_file.write( remote_data ) }	
		remote_data
	end
	return self.new( xml_data )
  end

  def doc
	@doc
  end




end


class MedlineTopic

	attr_reader  :tid, :name, :language, :synonyms, :lmtid, :summary

	def initialize( tid, language, name, synonyms, lmtid, summary )
		@tid = tid 
		@name = name
		@language = language 
		@synonyms = synonyms
		@lmtid = lmtid 
		@summary = summary
	end

  def descend_tags( children, tally )
	tag_sig = tally[:tag_sig]
    children.each { |child| 
		if child.elem? 
			tag_name = child.name
			if tag_name == "p" 
				tag_sig << "("
				descend_tags( child.children, tally )
				tag_sig << ")"
				tally[:n_ps] += 1
			elsif tag_name == "ul" 
				tag_sig << "["
				child_count = 0
				child.xpath("li").each { |li| 
					tag_sig << "," unless child_count == 0
					child_count += 1 
					descend_tags( li.children, tally ) 
				}
				tag_sig << "]"
				tally[:n_uls] += 1
			elsif tag_name == "a" 
				tag_sig << "^"
				tally[:ext_href] += 1 unless child.attr('href').start_with?( "http://www.nlm.nih.gov/medlineplus/" )
				tally[:n_hrefs] += 1
			elsif tag_name == "em" 
				tag_sig << "*"
				tally[:n_ems] += 1
			else
				tag_sig << "<#{tag_name}>"
				descend_tags( child.children, tally )
				tag_sig << "</#{tag_name}>"
			end
		elsif child.text? 
			stripped_text = child.text.strip
			tag_sig << "_" unless stripped_text == ""
			tally[:text] += stripped_text.size
		else
			tag_sig << "(#{child.node_type})"
		end
	}
  end

  TALLY_COUNTS = [:n_ps, :n_ems, :n_uls, :n_hrefs, :ext_hrefs, :text ]

  def tally
	summary_xml = Nokogiri::XML( "<summary>#{summary}</summary>" )
	summary_root = summary_xml.root
	tally = { :tag_sig => [] }
	TALLY_COUNTS.each { |tc| tally[tc] = 0 }
	if summary_root.nil?
		tally[:no_summary] = 1
	else
    	descend_tags( summary_root.children, tally ) unless summary_root.nil?
	end
	tally
  end

end


topics = []

vocab = MedlineVocab.for_date
vocab.doc.xpath("//MedicalTopic").each { |topic_node| 

	tid  = topic_node.at_xpath('ID').text.to_i rescue nil
	lang = topic_node["langcode"] rescue -1
	name = topic_node.at_xpath("MedicalTopicName").text rescue ""
	lmtid = topic_node.at_xpath('LanguageMappedTopicID').text.to_i rescue nil
	summary = topic_node.at_xpath("FullSummary")
	summary_xml = if summary.nil?
		nil
	else
	 	summary.text 
	end

	syns_node = topic_node.at_xpath("Synonyms") 
	description = if syns_node.nil?
		name
	else
		synonyms = [] 
		syns_node.xpath('Synonyms').each { |syn_node| synonyms << syn_node.text }
		"#{name} (#{synonyms.join(", ")})"
	end

	topic = MedlineTopic.new( tid, lang, name, synonyms, lmtid, summary_xml )

#	puts "%4d %2s %4d %s" % [topic.tid, topic.language[0..1], topic.lmtid || -1, description]

	topics << topic
}

en_topics = {}
es_topics = {}

puts "\nsummary html sigs: "

MAX_TEXT_SIZE = 16
text_size_histo = 0.upto(MAX_TEXT_SIZE).collect { 0 }

tids = []
topic_tallies = {}

topics.each { |t|

	if t.language == "English"
		en_topics[t] = t
	elsif t.language == "Spanish"
		es_topics[t] = t
	else
		puts "bogus language for topic #{t.tid}: #{t.language}"
	end

	tt = t.tally
    tally_s = "%4d %4d %2s %1d %1d %1d %2d %1d %4d %-30s %s" % [
		t.tid, t.lmtid, t.language[0..1], tt[:n_ps], tt[:n_ems], tt[:n_uls], tt[:n_hrefs], tt[:ext_hrefs], tt[:text], tt[:tag_sig], t.name
	]

	topic_tallies[t.tid] = tt
	tids << t.tid

	puts tally_s

	size_cat = tt[:text] / 100
	text_size_histo[size_cat] += 1
}

puts "\ntext sizes:"
text_size_histo.each_with_index { |n, x|
	puts "  %4d..%4d  %3d" % [x * 100, (x+1) * 100, n]
}  


summary_sigs = {}

0.upto( 42 ) do |n|

	topic = nil
	while topic.nil? do
		topic = topics[rand(topics.size)]
		if summary_sigs.key?(topic_tallies[topic.tid]) 
			topic = nil
		end
	end

	summary_sigs[topic_tallies[topic.tid]] = topic

end
	

puts "some random summaries (with unique signatures) for testing:"

sample_sums = {}

summary_sigs.each { |tally_sig, t|
    puts "\"#{t.name}\""
	sample_sums[t.name] = t.summary
}

File.open( "medline_topic_summaries.json", "w") { |json| json << sample_sums.to_json } 


